\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage[utf8x]{inputenc}
\makeatletter
\usepackage{cite}
\usepackage{float}
\usepackage{hyperref}
\@namedef{opt@inputenc.sty}{utf8}
\makeatother
\usepackage{url}    
\usepackage{CJKutf8}
\usepackage{multirow}
\usepackage{array}
\newenvironment{conditions}
  {\par\vspace{\abovedisplayskip}\noindent\begin{tabular}{>{$}l<{$} @{${}={}$} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}
\begin{document}
\title{
\begin{flushright}
\includegraphics[width=2.5cm]{logoUHi.jpg}\\
{\small
Data Analytics\\
Stiftung Universit{\"a}t Hildesheim\\
Marienburger Platz 22\\
31141 Hildesheim\\
Prof. Dr. Dr. Lars Schmidt-Thieme\\
}
\end{flushright}
\bigskip
\begin{center}
Thesis\\
Unsupervised Real-Time Time-Series Anomaly Detection\\
\end{center}
}
\author{Abdul Rehman Liaqat}
\date{271336, Liaqat@uni-hidesheim.de}
\maketitle

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables
\newpage

\begin{abstract}
Anomaly detection is a crucial task for machine learning due to wide-spread usage and type. In particular, it is worth noting that most data arising in industrial setups are of a streaming nature, thus restricting the range of standard anomaly detection tools. This thesis will identify the potential approaches to learn the identification of abnormal behavior from large-scale streaming data. An empirical comparison of state-of-the-art methods will to be extended by a novel technical contribution. In this thesis, the focus is particularly on streaming time-series Anomaly Detection which changes in nature with time and novel contribution will especially try to target this dynamic nature of time-series.
\end{abstract}
\newpage

\section{Introduction}
\subsection{Usage of streaming data}
With the increase in networking of objects, amount of data being generated is increasing. A big chunk of this data involves streaming data. Streaming data can be defined as data being generated continuously or with a continuous time interval. Such data is produced incrementally without having access to all of the data. Streaming data term is ususally used in context with big data. These streams of data is dumped into a large amount of unstructured databases called data lakes, which will be later treated in a batchwise fashion for the extraction of useful information. Streaming data is the most fresh form of data and is closest to being real-time, this is why any action or analysis done on top of data stream translates to near real-time action or analysis. Few examples of such real-time actions are e-commerce, network monitoring, fraud detection, pricing and bidding and so on.\\
\break
Since streaming data is generated continuously it is assumed that it will keep on being generated forever. Best example of such streaming data is internet of things (IoT) sensors which almost all the time generate streaming data. For example a heat sensor of exhaust fan of a data center is producing time series stream of data. This temperature can depicts many different facts about the data center and the condition of the fan itself. Increase in the temperature can signify high load on the data ceter hence higher usage and higher temperature generation. Similarly sudden change in the temperature can signify a failure of fan which should be replaced on urgent basis. Statistically, IoT data has grown from 4.4ZB (Zeta Bytes) to 44.4ZB with 50 billions devices. As the data is being generated continuously and endlessly, it is very likely that the data will change it's shape based upon external variables which are effecting the sensor or the data generating system itself. Taking the same example of exhaust fan temperature sensor. After changing the exhaust fan and installing a new one, it is very likely that the output tempreature time series stream is very different then the one generated by the previous exhaust fan temperature sensor. This signifies a possible permanent change in the streaming data which should be seriously taken if anykind of stream processing is being done.\\
\break
These IoT devices are covering a lot of different fields including a small temperature sensor installed in a room to ECG data to satellite communication data. Even videos are kind of streaming data since they include data points (frames) separated by a constant interval. Data generated from human mounted sensors such as smart watch is also a kind of streaming data. Since the data being generated is continuous and infinite in nature, it is necessary to have techniques which are using data the same way. In other words, to make use of this data it is necessary to build system which are also running live and changing themselves online. Similarly, it is important to keep the system running as often times the components which are generating streaming data are at the core of the system and in case of failure of these components, there is a danger of whole system being out of service. That is why it is necessary to find out any unusual behavior of the data being generated by the component. Early detection of such unusual behavior can help avoid any catastrophic impact on the system. It can also alarm the system before the break down of any thing hence acting as predictive prevention. This kind of unusal behavior is called anomaly and such detection of such unusual behavior is called anomaly detection.
\subsection{Usage of anomaly detection}
An anomaly is defined as significantly different data point or set of data points from the historical values or the expected values. There are various definitions of the "difference" between data points which leads to different types of anomalies. Detecting an anomaly helps in identifying abnormal behavior of a process with potentially useful information. For example, detecting an anomaly in the temperature sensor output data of exhaust sensor of a data center can signify a problem with the fan or the data center itself. Depending upon the type of anomaly it can translate to a failure in the data center or the break down of the fan itself. Now, in the systems such as data centers, detecting such anomaly as early as possible and taking action as swiftly as possible is extremely important. Such detection can save a catastrophic failure of the whole data center.\\
\break In normal machine learning and data science projects, anomaly and outlier detection is an important step which will help clean the data and provide useful insights. As described in \cite{Software2}, going forward, software development especially machine learning based software development will be divided into two parts. One part is the preparation of the data and the second part is the design and optimization of algorithms. Both of these steps are used iteratively. Interestingly, as described in the \cite{Software2}, more and more time is spent on accumulating, massaging and cleaning datasets. One major part of this process is outlier detection, anomaly detection and novelty detection. By detection of anomalies, it will become sufficiently easy for human expert to find the one data point in a heap of millions data points and then decide whether to remove that data or get more of the same data points. It also helps provide a useful insight and analysis of edge cases or extreme cases which can be of high importance.
\subsection{Usage of anomaly detection in streaming data}
As described above, anomaly detection is an important part of normal machine learning and data science projects. It is also very useful as first line of analysis on streaming data. It can act as real-time anomaly detection as the input to the anomaly detection is streaming data. This way one can detect any kind of anomaly occuring on the system real-time.
\begin{figure}[H]
\centering
        \includegraphics[width=\textwidth]{images/dataAnomalies/known/machine_temperature_system_failure.png}
    \caption{Machine Temperature System Failure}
    \label{machineTemperatureSystemFailure}
\end{figure}
 For example figure (\ref{machineTemperatureSystemFailure}) shows real-world temperature sensor data from an internal component of a large industrial machine. Anomalies are highlighted with red background. The second anomaly was a planned shutdown  hence there was an exceptional decrease in temperature. Last anomaly was a catastrophic system failure. Third anomaly just before the failure was a signal predicting the failure. If the anomlay detection system correctly detected the third anomaly, system level failure could have been avoided. Such examples motivates to define an ideal anomaly detection system. As suggested by \cite{ahmad2017unsupervised} the characteristics of an ideal anomaly detections system are:

\begin{enumerate}
\item Predictions must be made online which means that the algorithm must identify state $x_t$ as normal or anomalous before receiving the next data point $x_{t+1}$
\item The algorithm must learn continuously without a requirement to store the entire stream. 
\item The algorithm must run in an unsupervised, automated fashion. In other words the algorithm should not be fed any labeled data or shouldn't have any manual parameter changing.
\item Algorithms must adapt to dynamic environments and concept drift, as the underlying probability distributions often change.
\item Algorihtms should make anomaly detections as early as possible.
\item Algorithms should minimize false positives and false negatives.
\end{enumerate}

Each of the characteristics is backed by real world requirements and justification. These characteristics also leads to motivation of the problem and proposed methodology.
\subsection{motivation}
First characteristics is the continuous arrival of the data. We cannot have access to any future data. More specifically we will only have access to current time data as $x_t$ and previous data points as $x_{t-1},x_{t-2},x_{t-3},...$ and so on. This apply a constraint of finding the importance of data in the past and update the model online. Also as the data stream is continuous it becomes evident to have the system doing online prediction. Thus the first contraint of an anomaly detection algorithm is that it should predict online. \\
\break
Second characteristics of an ideal anomaly detection algorithm is to train itself in an online fashion. This characteristics is derived from the requirement that data is of streaming type. There is no knowledge of batch end size or ending of stream. Also streaming data has high velocity and volume which is why it is no suitable to store all previous training data and then train on it. Instead it is advisable to ideally train on latest data point or small batch of latest data points. Another possibility is to derive features from previous data and use them to train the algorithm at current time step. \\
\break
Third characteristics is to have an unsupervised algorithm. This is derived from the fact that streaming data is usually not labeled. Streaming data is meant to be of huge size and high velocity and to detect anomalies in real-time streaming data, it is difficult even for the experts in the domain. Also next characteristics also implies another requirement which is the cause of having anomaly detection algorithm unsupervised. \\
\break
Next characteristics of an ideal anomlay detection algorithm is that the algorithm must have the ability to adapt to dynamic environments and \textbf{concept drift}. Concept drift is a special concept for which a quick review of literature is required hence, starting with the official definition of anomaly then defining type of anomalies and basic properties of time series streaming data, we will define concept drift.
\newpage
An anomaly is defined as a data point $X_t$ or set of data points $X_{t-l:t}$ for which either of following is true:
\begin{enumerate}
    \item Probability of point $X_t$ belonging to a probability distribution $\phi$ is very less then the probability of previous data points $X_n$ where $n \leq t-1$. In other words:\\
    \begin{equation}
        P(X_t) \in \phi  \ll P(X_n) \in \phi 
    \end{equation}
    This type of anomaly is called point anomaly. Here $\phi$ is the probability distribution generating all the data points. An example of such anomaly is given in \ref{examleOfPointAnomaly}
    \begin{figure}[H]
\centering
        \includegraphics[width=0.8\textwidth]{images/dataAnomalies/ad/exchange-3_cpm_results.png}
    \caption{Cost Per 1000 impressions - An example of point anomaly}
    \label{examleOfPointAnomaly}
\end{figure}	
    \item Probability of points $X_{t-l:t}$ belonging to a probability distribution $\phi$ is very less then the probability of $X_{n-l:n}$ where $n \leq t-1$. In other words: \\
    \begin{equation}
        P(X_{t-l:t}) \in \phi  \ll P(X_{n-l:n}) \in \phi         
    \end{equation}
        This type of anomaly is called collective anomaly. An example of collective anomlay is given in \ref{examleOfCollectiveAnomaly}. This type of anomaly requires short term context and window of past set of values to be detected. Thus the anomaly detection algorithm should have history of past $t-w$ time steps or extracted features from these $t-w$ time steps. Here $t$ is the current time and $w$ defines the window of time.
        \begin{figure}[H]
\centering
        \includegraphics[width=0.8\textwidth]{images/dataAnomalies/ad/exchange-2_cpc_results.png}
    \caption{Cost Per Click with time - An example of collective anomaly}
    \label{examleOfCollectiveAnomaly}
\end{figure}

    \item Probability of point $X_t$ belonging to a probability distribution $\phi$ is almost same as the probability of previous data points $X_n$ where $n \leq t-1$ but the probability of point $X_t$ belonging to a probability distribution $\theta$ is very less than the probability of point $X_p$ belonging to $\theta$. Here In other words:\\
    \begin{equation}
        P(X_t) \in \phi  \approx P(X_n) \in \phi 
    \end{equation}
    \begin{equation}
        P(X_t) \in \theta  \ll P(X_n) \in \theta 
    \end{equation}
    Here $\theta$ and  $X_p$ are probability distribution and data points. $theta$ is a distribution defined to a set of local points $X_p$ where $p \leq t$ and $p$ is a set of indices. 
    This type of anomaly is called Contextual anomaly. Contextual anomaly require both short term and long term contenxtual information which makes it difficult to detect. It also enforce a requirement to the algorithm to have the ability to be able to store both long term and short term important information.
\end{enumerate}
\begin{figure}[H]
\centering
        \includegraphics[width=\textwidth]{images/dataAnomalies/aws/rds_cpu_utilization_cc0c53.png}
    \caption{AWS CPU Utilization Concept Drift}
    \label{awsCpuUtilizationConceptDrift}
\end{figure}
\subsection{Constraints}
In many cases there is a system change which causes a permanent change in the probability distribution being generated by the data and this change is called \textbf{concept drift}. An example is in figure \ref{awsCpuUtilizationConceptDrift}, where software updates and configuration changed can change the behavior of the system forever. Now the system must adapt to detect anomalies according to the new type of data. To do that the model must first recognize that if it is a concept drift and then change itself accordingly, that too in an unsupervised and automated way. There is also an intuitive meaning behind the name of Concept drift.\\
\break
Considering that there is an underlying probability distribution in every time series and this underlying distribution is named Concept of that time series such as
\begin{equation}
Concept =  P_t(X)
\end{equation} 
The the concept drift occurs between two times t and u when the distribution or concept changes as
\begin{equation}
    P_t(X) \neq P_u(X)
\end{equation}
And the new data points are generated from the second distribution $p_u(X)$ onward rather then the original $P_t(X)$ for a length of time $T$. This time $T$ is decided by the domain knowledge and frequency of data points.
As in real life systems it is highly likely that there will be a change in the concept of the time-series hence happening of concept drift is very likely and possible. For example, there will be a concept drift in the time-series output of a heat sensor measuring the temperature of a motor of exhaust fan and the motor of the fan is changed. Thus it is necessary for our system to first recognize the concept drift. If there exists a concept drift then the model should adapt itself swiftly to avoid false positives. Similarly if there is not a concept drift then the model should not give much learning weight to these readings. Thus the model adaption according to presence of concept drift is necessary. This leads to fourth characteristics of an ideal anomaly detection algorithm that it should adapt itself according to the concept drift.\\
\break
In streaming applications it is also very useful to detect the anomaly as early as possible. For example in the streaming data of cardiac patient's heart; earlier detection can help in taking emergency measures to stop the onset of heart attack. Obviously detecting them a little earlier is way better than later. This early detection acts as an alarm and will really fulfill the purpose of alarm when enough time is remaining to take action to avoid catastrophic failure.
So, the fifth characteristics of an  ideal anomaly detector is devised from this requirement. If the predictions are made online or as early as possible such as before the arrival of next data point $x_{t+1}$, early detection of anomlay can be made possible. \\
\break
Of course, having this early detection or online prediction property of an algorithm comes with drawbacks. For online prediction, algorihtm has to be fast which in turn constrain the requirement of having the less number of computations hence rather simple architecture. This is why, the algorithm will have an extra senstivity, which can cause many false alarms. Therefore, there is a trade-off between false alarms and  true positives. One can setup variable sensitive algorithm which can be trained according to the importance of false positive, true positive and false negatives. This property is also introduced in the proposed method ahead.\\
\break
Lastly, it is obvious that the anomlay detection algorithm must have ideally zero false positive and false negative rate and hunderd percent true postivie and true negative rate.
Of course, it is difficult to fulfill all the requirement. Still the best detection algorithm will try to maximize the completion of all above. Secondly based upon the requirement of the system few requriements can also be relaxed or others few requirements can be given preference. For example, in case of heart's patient having anomaly detected as early as possible with extremely highly true positive will be necessary. In the process, few false postives can be afforded. On the other hand in a supply chain management system, where there are already a lot of alarms about low inventory are ringing, having false negatives can be afforded.
\newpage
Concluding, with the requriements given above it becomes obvious that many current anomaly detection algorithms do not fulfill them as discussed in the related work section. We tried to create a system which fulfill these requirements to their maximum.
\subsection{General framework of anomaly detectors and summary of each step}
Generally, most of anomlay detection frameworks follow a pipeline of steps.These steps are described in figure \ref{generalAnomalyDetectionFrameWork}. We will be summarizing each step to provide the extent of problems and possible area of innovations available in anomlay detection system and define our contribution along the way.
\begin{figure}[H]
\centering
        \includegraphics[width=\textwidth]{images/generalAnomalyDetectionFrameWork.png}
    \caption{General Anomaly Detection Framework}
    \label{generalAnomalyDetectionFrameWork}
\end{figure}
First step is to pre-process the input data. Usually this step is performed to engineer features or do normalization of the data. That way the algorithm will be able to learn better.  Preprocessing step can also be used to generate features from the data to be used as long term contenxtual information. Although it would be better to have domain expertise for the creation of such features. While doing normalization, one fact should be kept in mind that the regular methods of data normalization might not be valid for streaming data. For example, in case of normalization using standard deviation, it is required to have the mean and standard deviation of the data before hand, which is not possible in case of streaming data. Hence either modified version of normalization using standard deviation can be used or some other kind of normalization is prefered.\\
\break
Second step is to estimate the underlying probability distribution. Instead of estimating the probability distribution directly, most of the time a model is built upon the streaming data such that the prediction of the model denoted by $Y_t$ at time $t$ is closed to the actual value $X_t$ at time $t$. Thus it is assumed that the model will automatically learn the underlying distribution of the data. Now depending upon the type of input and output required, different kind models can be trained. Assuming that any past $t-w$ data points are stored, one model can be trained to predict the point $x_{t+1}$ using data from $x_{t-w:t}$. Another kind of model will instead try to reconstruct the whole input stream. These models are based upon autoencoders. Usually the difference of the output value $Y_t$ and actual value $X_t$ gives us some significant information about the data at $X_t$. As the model prediction is actually the prediction of modeled distribution of data hence any significant difference of the predicted or output value and actual or input value respectively, can be hint of an anomaly. Also the model should follow the characteristis of an ideal anomaly detection algorithm defined above. On top of that, there is another open quenstion about the complexity and evaluation criterion of the model. The model can have very less predictive error but still the whole anomlay detection system might not be able to detect the anomaly. Similarly a model can be relatively less accurate but still be able to detect all types successfully. The ability of detecting a concept drift and then adapting itself should also be the part of model. The model should be built carefully so as it can learn online and is not fully converged as it will be trained continuously with incoming of data.\\
\break
Next step would be to score the output of the model. At this moment we will use the previously estimated probability distribution as model and types of anomalies defined above to score the incoming data point. Scoring each data point is also an important area of innovation. Each point should be scored if it is an anomaly or not. The score should be based upon the history of model predictions and actual point plus current prediction and actual value. The score will try to quantize each data point according to the types of anomalies described above. Depending upon the type of model algorithm used, anomlay score can have different ranges. This is not the final score to be considered as it passes through a post-processing step which is also very important in removing the noise and building far and near contextual connections.\\
\break
Afterwards the score is passed through a post-processing step. In this step possibly normalization and probabilistic likelihood estimation is applied on top of the previously calculated anomaly score. In other words previously calculated anomaly score is transformed between the range of $0$ and $1$ thus scoring each data point between defined range. This constraint helps in defining a common threshold for all types of data sets in the next step. This step is also important and is an important area of innovation. It can be used to compliment the previous step of score calculation. One can also apply another model at this point which can be used to capture the long term and short term patterns in the anomaly scores itself.\\
\break
After post-processing, we can use the score to actually rank each incoming data point among previously existing data points. To label each data point as anomaly or not anomaly a thresholding procedure is necessary. Depending upon the type of post-processing extreme cases are considered as anomalies. Since all types of data is subjected to a defined range, it is easier to define a common threshold for all.
\subsubsection{Our Contribution}
We contributed in different areas of general anomaly detection framework.\ref{generalAnomalyDetectionFrameWork}. First contribution was the implementation of Numenta Anomaly Detection Benchmark (NAB) \cite{NAB}. NAB is an anomlay detection benchmark which comes with labelled dataset, customized scoring mechanism and benchmark algorithms to test against. This benchmark is an open source project implemented in Python2.7. So, in the first step NAB was implemented and results of benchmark algorithms were reproduced. Additionally, system was setup to test proposed methodologies using same dataset and scoring function.\\
\break
Second contribution is the implementation and testing of multi-step prediction algorithms. Three different types (fully connected, convolutional and LSTM) based multi-step prediction architecture were designed. Multi-step prediction algorithm, in short, refers to predicting multiple time step values at once. Changing the length of these steps from $1$ to $5$ provided interesting insights and helped break few benchmarks.\\
\break 
Third contribution is the implementation and testing of autoencoder based algorithms. These are also based upon three different types, just like previous one. Next contribution is in the form of autoregressive input of the loss from previous algorithms. This contribution serves two purposes. One is to improve the prediction accuracy of the algorithm especially because we are not using all previous data instead a small moving window as $x_{t-w}$ where $w$ is window size and it is tested for different values. Second is to have the ability to control the algorithm's response to concept drift. This method also proved to be useful as we passed few benchmarks along with few interesting insights.
\\
\break
Next contribution is the implementation of anomaly liklihood calculation of anomlay score as a post-processing step. This is the same implementation as described in \cite{ahmad2017unsupervised}. Similarly, a second type of post-processing step is inspired by simple min-max normalization. We tried rolling min-max normalization which proves to provide better results than anomaly liklihood method on the same dataset.
\subsubsection{Details of sections coming up-next}
In the next sections we will first define the state of the art methods and related work needed as foundation for the understanding of proposed methodology. Next in the proposed methodology, we will describe each contribution and architecture in details. Then experimental setup and data set used will be explained in the next section. Afterwards results of these experiments and their comparison to other benchmarks will be done. Lastly, we will conclude with discussion on the experiments done providing useful insights, failed tries and future research direction.
\newpage
\section{Related Work and State-of-the-art}
For the understanding of unsupervised anomaly detection in streaming data, it is important to have a summarized review of time series and it's features, general anomaly detection methods and general anomaly detection methods applied on streaming data. We will start with a quick review of time series.\\
\break
Time series is usually defined as a series of data points indexed in time. A single variable where the value of variable is time series and the only other information available for each data point is the time of occurence, is called uni-variate time series while if there are multiple variables for each time index such as: $X = \{ x^{1},x^{2},x^{3},x^{4},..,x^{m}\}$ where each point $x^{t} \in R^m$ in the time series is an m-dimensional vector $\{x_{1}^{t},x_{2}^{t},x_{3}^{t},....,x_{m}^{t}\}$. This is called multi-variate time series as defined in \cite{stackedLstmFirst}. 

\section{Proposed method}
Here we will again use figure \ref{generalAnomalyDetectionFrameWork2}, as generic framework for anomaly detection system and start with describing each individual component design for the proposed methodology. 
\subsection{General anomaly score based architecture and detailed explanation}
\subsubsection{preprocessing}

\begin{figure}[H]
\centering
        \includegraphics[width=\textwidth]{images/generalAnomalyDetectionFrameWork.png}
    \caption{General Anomaly Detection Framework}
    \label{generalAnomalyDetectionFrameWork2}
\end{figure}

As a first step, raw input of uni-variate time series is fed. Since the data is in the form of streaming format, hence we don't have any information about data beyond $t$. Instead of just using the value at time $x_t$, we actually process a window of size $x_{t-w}$. The value of $w$ is used as a hyperparameter. Although it is dependent upon different data sets and types of algorithms but after testing a few different values, $w$ is set to $50$. Hence as a first pre-processing step, $x_t$ is fed to buffer which will pop the last value in the queue and push $x_t$ in. Using such window based input comes with few benefits and drawbacks. Since window size is small it is easier and quicker to process. Although in return, it turns simple time series prediction into a sequence to sequence prediction problem which might not able to take a time series features and properties into account. This was one of the problem faced with our proposed methodologies which we tried to cover using auto-regressive component. Using window made us ignroe the value of trend, seasonality, autocorrelation and similar imporant concept related to time series.\\
\break
Another important pre-processing step is normalized using equation \ref{minMaxNormalization}. Normalization helps the algorithm learn faster and since all type of datasets have same input range, it helps in better generalization. One assumption made for the normalization is that we already know the possible minimum and maximum values of the data which is generally true in most real life cases. Thus all of the data sets are normalized before feeding into the algorithm.
We use min-max normalization to make sure that all input values are limited between $0$ and $1$. By including normalization of input as first step makes it possible to be able to use the same anomaly detection model framework for all kind of input data range. Min-max normalization can be defined as
\begin{equation}
    z = \frac{x - min(x)}{max(x) - min(x)}
    \label{minMaxNormalization}
\end{equation}
\subsubsection{algorithm}
Now that we have availibility to the preprocessed input, it is time to describe the design of proposed algorithms. All of the proposed algorithms are designed to consider the characteristics of an ideal anomaly detection algorithm. Since we cannot store the whole data and have access to future data, as it is one of the characteristics, that is why we are keeping a small batch of input data which can be easily stored in memory of the system. Other two characteristics, which are related to online training and prediction, enforce the algorithm to have less number of computations.\\
\break
\subsection{Multistep prediction architecture}
First type of architecture used is multistep prediction architecture. In this type of architecutre sequence to sequence prediction task is trained. Input sequence for datapoint $X_t$ at time $t$ will be $X_{t-w-l:t-l}$. Here $w$ is the window size of input and $l$ is the length of output sequence. Thus the output will be $Y_{t-l:t}$. Intuitively, it means to take a sequence in the past and predict in the past starting from the end of the input sequence.
More specifically the output prediction when the input sequence $X_{t-w-l:t-l}$ is fed to the trained function $h$ will be:
\begin{equation}
Y_{t-l:t} = h(X_{t-w-l:t-l})
\end{equation}
The input will be a uni-variate vector of size $w$ and the output will be another uni-variate vector of size $l$. The final loss for which these multistep prediction architecture algorithms are trained against is mean squared error or MSE defined as:
\begin{equation}
L(x,y) = \frac{1}{l}\sum(Y_{t-l:t}-h(X_{t-w-l:t-l}))^2
\end{equation}
Here $h$ is the 
Now we use different architecture to train the function $h$. Other then that, the window size $w$ and output sequence length $l$ is also a hyperparameter. Main three types of architecture designed and tested through Multistep-Ahead prediction based architecture are:
\begin{enumerate}
	\item Fully connected architecture
	\item CNN based architecture
	\item LSTM based architecture
\end{enumerate}
Here size of architecture is usually kept smaller and compact. The reason is to have the ability to train and predict online and having smaller faster architecture is important.

\subsection{Fully connected multistep ahead prediction architecture}
In fully connected multistep ahead prediction architecture, we use three fully-connected layers. Input is a one dimensional vector of window size $w$ which is passed to a fully connected layer of $50$ cells. Next two fully connected layers with $25$ and $10$ number of neurons are set up. Lastly there is another fully connected layer with the number of neurons equal to $l$. Here $l$ is multistep ahead prediction length or output sequence size. We test the architecture for different lenghts of $w$ and $l$.
\begin{figure}[H]
\centering	
        \includegraphics[width=0.5\textwidth]{images/architecture/NnMultistepAheadPrediction.png}
    \caption{Fully connected Multistep Ahead Prediction with input length W and output length L}
    \label{generalAnomalyDetectionFrameWork}
\end{figure}

\subsection{Convolutional multistep ahead prediction architecture}
In convolutional mutlistep ahead prediction architecutre, input is fed to a convolution layer with $8$ different kernels of $1 \times 4$ with stride $2$. Following is another layer of the same dimensions. Then we have two layers of $10$ different kernels of $1 \times 3$ with stride $2$. The last convolution layer consists of $12$ kernels of dimension $1 \times 2$ with no stride. Activation function for all the neurons of convolution layers is relu. Next a fully connected layer with $10$ neurons is set up whose activation function is relu. Lastly the output layer is a fully connected layers consisting of $L$ neurons where $L$ describes the size of output sequence.
\begin{figure}[H]
\centering
        \includegraphics[width=0.8\textwidth]{images/architecture/CnnMultistepPrediction.png}
    \caption{Convolutional Network based Prediction Network}
    \label{generalAnomalyDetectionFrameWork}
\end{figure}
\subsection{LSTM multistep ahead prediction architecture}
LSTM based multistep ahead prediction architecture is rather simple. As usual input is a uni-variate vector of size  $W$ which is fed to $50$ concatenated LSTM cells with Relu activation. Lastly a fully connected layers with $L$ neurons and no activation is kept as an output layer.
First type of algorithms used are multistep prediction algorithms. Here the algorithm is trained for sequence to sequence prediction. Multistep prediction method for unsupervised anomaly detection is motivated from \cite{stackedLstmSecond}. More specifically let $T_{(t-L-1):(t-1)}$ be the input data is the form of  small window taken from time series. The starting point is $t-L-1$ where $L$ is the window size and last data point is taken from $t-1$ which is the data point at previous time step. This data window is used to predict the time series value at time $t$. To predict at time $t$ various different kind of functions as baselines using latest architectural components are designed. Generally the output of such a function would be
\begin{equation}
f(T_{(t-L-1):(t-1)}) = \hat{f}(t)
\end{equation} 
Thus the function $f$ in prediction based models map data points as: $f: L \mapsto 1$ where $L$ is the window size and output is the prediction of value at current time. For optimization of function $f$, the difference between time series value at current time step and predicted value at current time is taken. More specifically the objective function will be
\begin{equation}
min |\hat{f}(t) - f(t)|
\end{equation}
That is to minimize the difference between time series value at time $t$ and predicted time  
In the algorithm part, we use different kind of algorihtms with few things in common. For all kind of algorithms the input values are sequence of length $W$ and output values are also a sequence whose size is tested from $1$ to $5$. Another important thing to remember is that the output is different for autoencodre based architectures and multistep prediction architectures. More details are given below.
We take the simple mean squared distance as anomaly score. So at each time step, we take the difference between the output sequence and the actual real sequence using mean squared distance. The same is also used for training of each algorithm. After doing a forward pass prediction and calculating the anomaly score using mean squared distance, we use the anomaly score to back-propagate the error using one iteration.
Next post-processing step is important as literature shows that this step makes a significant difference in the improving the score of an anomaly detector. There are two different kind of post-processing techniques used. First technique is suggested by \cite{ahmad2017unsupervised} and is called anomaly liklihood estimation. Second technique is a modification of simple min-max noarmalization. We perform a rolling min-max normalization.
First technique is the usage of anomaly likelihood as described equation.
The anomaly likelihood is a probabilistic metric defining how anomalous the current state is based on the prediction history.To compute the anomaly likeli-
hood we maintain a window of the last W error values. We model
the distribution as a rolling normal distribution where the sample
mean $\mu_t$ and variance $\sigma^2_t$, are continuously updated from previ-
ous error values as follows:
s\begin{equation}
\mu_t = \frac{\sum_{i=0}^{i=W-1} S_{t-i}}{W}
\end{equation}
\begin{equation}
\sigma^2_t=\frac{\sum_{i=0}^{i=W-1} (S_{t-i}-\mu_t)^2}{W-1}
\end{equation}

We then compute a recent short term average of prediction
errors, and apply a threshold to the Gaussian tail probability
to decide whether or not to declare an anomaly. 3
We define the anomaly likelihood as the complement of the tail
probability:
\begin{equation}
L_t = 1-Q (\frac{\tilde{\mu_t}-\mu_t}{\sigma_t})
\end{equation}
and here $\tilde{\mu_t}$ is defined as:
\begin{equation}
\tilde{\mu_t} = \frac{\sum_{i=0}^{i=w-1}S_{t-i}}{w}
\end{equation}
Here $w \ll W$. We use $w$ for short term moving average and $W$ for long term moving average. This will give us a probability likelihood of a data point being an anomaly. Next step is to threshold the anomlay by setting up a threshold which is defined by user and is a hyperparameter. The threshold is set to $1-\epsilon^{-5	}$
Second method is moving mix-max normalization, which is rather simple but quite effective. We take the maximum and minimum value of the past and current data at a given point in time $T$ and use it to normalize the incoming anomaly score value. If the new anomaly score value is greater than the past maximum value then the maximum value is updated. Similarly if the new anomaly score value is less than the past minimum value then the minimum value is updated. In the beginning of training, ususally convergence loss is higher and it does not make sense to compare it with the values calculated later on that is why first $N$ value of the anomaly score are skipped before we start considering the maximum and minimum value. The value $N$ is usually set around $100$.
\break
 series value at time $t$ using time series value from $T_{(t-L-1):(t-1)}$.
\subsection{Autoencoder based architecture}
An autoencoder is a network which is trained to copy its input to its output, with the typical purpose of dimension reduction - the process of reducing the number of random variables under consideration. It features an encoder function to create a hidden layer (or multiple layers) which contains a code to describe the input. There is then a decoder which creates a reconstruction of the input from the hidden layer. An autoencoder can then become useful by having a hidden layer smaller than the input layer, forcing it to create a compressed representation of the data in the hidden layer by learning correlations in the data. This compressed representation is actually summarized version of input. This way for the anomaly input values, summarized version will not output very similar output and hence ending up creating big reconstruction loss.
The backpropagation will try to  $h_{W,b}(x) \approx x$ , so as to minimise the mean square difference:
\begin{equation}
L(x,y) = \sum(x-h_{W,b}(x))^2
\end{equation}
Similarly for time series let $X_t$ be the input value of the streaming data at time $t$ then the input of autoencoder based architecture will be $X_{t-w:t}$ and output will be $Y_{t-w:t}$ as $Y$ is the predicted reconstruction of the input. 
\begin{equation}
Y_{t-w:t} = h(X_{t-w:t})
\end{equation}
The reconstruction loss is defined as:
\begin{equation}
L(x,y) = \frac{1}{w}\sum(Y_{t-w:t}-X_{t-w:t})^2
\end{equation}
$\gg \ll$ picture of an autoencoder

\begin{figure}[H]
\centering
        \includegraphics[width=0.4\textwidth]{images/architecture/LstmMultistepaheadPrediction.png}
    \caption{LSTM based Prediction Network}
    \label{generalAnomalyDetectionFrameWork}
\end{figure}
\subsection{Autoencoder architecture}
\subsection{Fully Connected Autoencoder architecture}
\subsection{Convolutional Autoencoder architecture}
\subsection{LSTM Autoencoder architecture}
\subsection{Recency concept}
\subsection{Post-processing}
Post-processing is a very important part of anomlay detection. This step is called anomaly scoring. Each We tested two different kind of post-processing techniques.First technique is suggested by \cite{ahmad2017unsupervised} and is called anomaly liklihood estimation. Second technique is a modification of simple min-max noarmalization. We perform a rolling min-max normalization. \\
\break

\subsection{Thresholding}

\subsection{Parameterinzing the anomaly score}
\subsection{Scoring}
Another benefit of using NAB is that it comes with a customized scoring and evaluation mechanism which is quite suitable for the online anomaly detection algorithms. Each algorithm is tested against three different profiles. Each profile provides a specific weight to true positive (TP), false positive (FP) and false negative (FN). This way an algorithm can be tested according to the requirement of the system.\\
\break
The value of the TP weight in the default application profile is 1.0. If a
user wants to emphasize the importance of correct anomaly detection during the
benchmark run, then the TP weight metric can be increased. This will increase
the amount that the score is incremented every time an anomaly is detected
correctly. Accordingly, if the user wants to deemphasize the importance of
correct anomaly detection during the benchmark run, then lowering the value of
the TP weight will decrease the amount added to the score every time an
anomaly is detected correctly.\\
\break
The value of the FP weight in the default application profile is 1.0. If a user
doesn’t care as much about false positives being detected, then decreasing this
value will decrement the score by a lesser amount every time an anomaly is
incorrectly identified. Accordingly, if the user wants to emphasize a low FP rate,
then increasing the value of FP will decrement the score by a greater amount
every time an anomaly is incorrectly identified.\\
\break
In case of FN weight, the score is reduced by this amount once for each anomaly
which is not detected at all. The value of the FN weight in the default application
profile is 1.0. If a user wants to make it more important that the detector never
miss a real anomaly, then increasing the FN weight will decrement the score by a
greater amount when an anomaly is missed. If the user cares less about true
anomalies being missed, then decreasing the value of the FN weight will
decrement the score by a lesser amount when an anomaly is missed.\\
\break
With the anomaly windows defined to be 10\% of a given data file, true positives are limited to 10\% of the data. Yet false positives can
occur in 90\% of the data. That is, of all the timesteps in each data file, only 10\%
are eligible to be true positives (within a window), while 90\% can be false
positives (outside a window) . Thus we scale the score contribution of false
positives such that they have the same cumulative weight as true positives – i.e.
the score contributions from false positives are divided by 9. This is reflected in
the application profiles below.\\
\break
As described above, with the combination of true positive (TP) weight, false positive (FP) weight and false negative (FN) weight, NAB creates three application profiles. The main one is \textbf{standard profile} which attributes equal weight
across the scoring metrics. To be specific TP weight is set to 1, FP to 1 and FN to 0.11. \\
\break
Second profile rewards a detector that has a
very low FP rate; they would rather trade off missing a few true anomalies rather
than getting multiple false positives.The scoring weights of are set as following:
\begin{itemize}
\item true positive weight is set to 1. This will give full credit to properly detected anomalies. 
\item false positive weight is set to 0.22. This will decrease the score for any false positive.
\item false negative weight is set to 0.5. This is bigger than FP weight. Thus the algorithm will be rewarded for low false positives.
\end{itemize}
Last application profile will reward a detector that doesnot
miss any true anomalies; they would rather trade off a few false positives than
miss any true anomalies. The scoring weights are set as true positive weight is set to 1. false positive weight is sset to 0.055. False negative weight is set to 2.\\
\break

NAB then uses above profiles to come with a scoring function. The given scoring function is built around the ideal real-world anomaly detector. The characteristics of an ideal real-world anomaly detector should be:
\begin{enumerate}
\item detects all anomalies present in the streaming data
\item detects anomalies as soon as possible, ideally before
the anomaly becomes visible to a human
\item triggers no false alarms (no false positives)
\item works with real time data (no look ahead)
\item is fully automated across all datasets (any data
specific parameter tuning must be done online without human
intervention)
To promote early detection NAB defines anomaly
windows. Each window represents a range of data points that is
centered around a ground truth anomaly label.
\end{enumerate} 
\begin{figure}[H]
\centering
        \includegraphics[width=\textwidth]{images/nabScoringExample.png}
    \caption{Scoring example for a sample anomaly window, where the values
represent the scaled sigmoid function. he first
point is an FP preceding the anomaly window (red dashed lines) and
contributes -1.0 to the score. Within the window we see two detections, and
only count the earliest TP for the score. There are two FPs after the window.
The first is less detrimental because it is close to the window, and the second
yields -1.0 because it’s too far after the window to be associated with the true
anomaly. TNs make no score contributions. The scaled sigmoid values are
multiplied by the relevant application profile weight. The NAB score for this example would calculate as: $-1.0A_{FP} + 0.9999A_{TP} - 0.8093A_{FP} - 1.0A_{FP} $}
    \label{nabSigmoidScoringFunction}
\end{figure}
To promote early detection NAB defines anomaly
windows. Each window represents a range of data points that is
centered around a ground truth anomaly label. Fig. 2 shows an
example using the data from Fig 1. A scoring function
(described in more detail below) uses these windows to
identify and weight true positives, false positives, and false
negatives. If there are multiple detections within a window, the
earliest detection is given credit and counted as a true positive.
Additional positive detections within the window are ignored.
The sigmoidal scoring function gives higher positive scores to
true positive detections earlier in a window and negative scores
to detections outside the window (i.e. the false positives).
These properties are illustrated in Fig. 3 with an example.
How large should the windows be? The earlier a detector
can reliably identify anomalies the better, implying these
windows should be as large as possible. The tradeoff with
extremely large windows is that random or unreliable
detections would be regularly reinforced. Using the underlying
assumption that true anomalies are rare, we define anomaly
window length to be 10\% the length of a data file, divided by
the number of anomalies in the given file. This technique
allows us to provide a generous window for early detections
and also allow the detector to get partial credit if detections are
soon after the ground truth anomaly. 10\% is a convenient
number but note the exact number is not critical. We tested a
range of window sizes (between 5\% and 20\%) and found that,
partly due to the scaled scoring function, the end score was not
sensitive to this percentage. Different applications may place different emphases as to
the relative importance of true positives vs. false negatives and
false positives. For example, the graph in Fig. 2 represents an
expensive industrial machine that one may find in a
manufacturing plant. A false negative leading to machine
failure in a factory can lead to production outages and be
extremely expensive. A false positive on the other hand might
require a technician to inspect the data more closely. As such
the cost of a false negative is far higher than the cost of a false
positive. Alternatively, an application monitoring the statuses
of individual servers in a datacenter might be sensitive to the
number of false positives and be fine with the occasional
missed anomaly since most server clusters are relatively fault
tolerant.To gauge how algorithms operate within these different
application scenarios, NAB introduces the notion of
application profiles. For TPs, FPs, FNs, and TNs, NAB applies
different relative weights associated with each profile to obtain
a separate score per profile. \\
\break
NAB includes three different application profiles: standard,
reward low FPs, and reward low FNs. The standard profile
assigns TPs, FPs, and FNs with relative weights (tied to the
window size) such that random detections made 10\% of the
time would get a zero final score on average. The latter two
profiles accredit greater penalties for FPs and FNs,
respectively. These two profiles are somewhat arbitrary but
designed to be illustrative of algorithm behavior. The NAB
codebase itself is designed such that the user can easily tweak
the relative weights and re-score all algorithms. The
application profiles thus help evaluate the sensitivity of
detectors to specific applications criteria.The combination of anomaly windows, a smooth temporal
scoring function (details in the next section), and the
introduction of application profiles allows researchers to
evaluate online anomaly detector implementations against the
requirements of the ideal detector. Specifically the overall
NAB scoring system evaluates real-time performance, prefers
earlier detection of anomalies, penalizes “spam” (i.e. FPs), and
provides realistic costs for the standard classification
evaluation metrics TP, FP, TN, and FN.\\
\break
Now to compute NAB score for an algorithm and a given application profile we use following procedure. Let $A$ be the application profile under consideration, with $A_{TP}$, $A_{FP}$	, $A_{FN}$ and $A_{TN}$ the corresponding weights for true positives, false positives, false negatives and true negatives.These weights are bounded $A_{TP} \geq 0$, $A_{TN} \leq 1$ and 
$A_{FP} \leq -1$, $A_{FN} \leq 0$. Let $D$ be the set
of data files and let $Y_d$ be the set of data instances detected as
anomalies for datafile d. (As discussed earlier, we remove
redundant detections: if an algorithm produces multiple
detections within the anomaly window, we retain only the
earliest one.) The number of windows with zero detections in
this data file is the number of false negatives, represented by $f_d$. The following scaled sigmoidal scoring function defines
the weight of individual detections given an anomaly window
and the relative position of each detection:
\begin{equation}
\sigma^{A}(y) = (A_{TP} - A_{FP})(\frac{1}{1+e^{5y}})-1
\label{sigmoidEquation}
\end{equation}
In equation (\ref{sigmoidEquation}), $y$ is the relative position of the detection within the
anomaly window. The parameters of the equation are set such that
the right end of the window evaluates to $\sigma(y = 0.0) = 0$ and it yields a max and min of $A_{TP}$ and $A_{FP}$, respectively. Every detection outside the window is counted as
a false positive and given a scaled negative score relative to the
preceding window. The function is designed such that
detections slightly after the window contribute less negative
scores than detections well after the window. Missing a
window completely is counted as a false negative and assigned
a score of $A_{FN}$. The raw score for a data file is the sum of the scores from
individual detections plus the impact of missing any windows:
\begin{equation}
S^A_d = (\sum_{y \in Y_d} \sigma^A(y)) + A_{FN}f_d
\label{weightsAccumulation}
\end{equation}
Equation (\ref{weightsAccumulation}), accumulates the weighted score for each true positive
and false positive, and detriments the total score with a
weighted count of all the false negatives. The benchmark raw score for a given algorithm is simply the sum of the raw scores
over all the data files in the corpus:
\begin{equation}
S^A = \sum_{d \in D} S^A_d
\label{allScore}
\end{equation}
The final reported score is a normalized NAB score computed as follows:
\begin{equation}
S^A_{NAB} = 100 \times \frac{S^A - S^A_{null}}{S^A_{perfect} - S^A_{null}}
\label{scoreNormalization}
\end{equation}
Here we scale the score based on the raw scores of a “perfect”
detector (one that outputs all true positives and no false
positives) and a “null” detector (one that outputs no anomaly
detections). It follows from equation (\ref{scoreNormalization}) that the maximum (normalized) score a detector can achieve on NAB is 100, and an algorithm making no detections will score 0.

\section{Empirical Formulation and Experiments}
\subsection{Dataset}
To experiment with proposed method and campare them with state-of-the-art results Numenta Anomaly Benchmark (NAB) was used. Numenta is a benchmark specifically designed for online time series anomaly detection. It is first of its kind as NAB tries to cover all type of anomalies. Also they have come up with a custom scoring function to map the characteristics of an ideal online anomaly detector.\\
\begin{figure}[H]
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/artificial/art_daily_flatmiddle.png}
    \caption{Artificial with sudden flat-middle}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/artificial/art_daily_jumpsdown.png}
    \caption{Artificial with sudden jumps-down}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/artificial/art_daily_jumpsup.png}
    \caption{Artificial with sudden jumps-up}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.5	\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/artificial/art_daily_nojump.png}
    \caption{Artificial with sudden flat}
  \end{subfigure}
  \caption{Examples of artifical anomaly data set}
  \label{artificialDataPlots}
\end{figure}
Using NAB provides with many benefits. First benefit is that it is a benchmark dataset which $58$ various univariate time series, each with timestamp as index and value. Length of each time series ranges from $1000$ to $22000$ data points. This provides us with enough variability in data. These $58$ time series are from six different categories. These categories include artificially generated time series, times series gathered from advertisement industry related data such as click through rate (CTR), AWS usage metrics, server traffic data, tweets volume time series and known cause anomaly which has the a solid reason for the labeled anomaly.\\
\break
The diversity of these categories provide the second benefit. With the diversity almost all type of anomalies are covered hence each algorithm can be tested against each type. Artificial datasets further contains time series with anomalies and without anomalies. Datasets without anomalies contain only normal patterns and no anomaly thus any predicted anomaly will be a false positive here. This way one can test false positive prediction tendency of an algorithm. \\
\break
In NAB, concept drift is given a special importance that is why many datasets contains concept drift. These datasets are mostly real life ones. Example of these are following:

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/aws/ec2_cpu_utilization_5f5533.png}
    \caption{Artificial with sudden flat-middle}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/aws/grok_asg_anomaly.png}
    \caption{Artificial with sudden jumps-down}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/aws/rds_cpu_utilization_cc0c53.png}
    \caption{Artificial with sudden jumps-up}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5	\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/aws/rds_cpu_utilization_e47b3b.png}
    \caption{Artificial with sudden flat}
  \end{subfigure}
  \caption{Examples of Concept drift in AWS data sets}
  \label{AwsConceptDrift}
\end{figure}

Similarly almost all kind of anomalies exist in the dataset. For example for point anomaly we can see that in following.

\begin{figure}[H]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/twitter/Twitter_volume_FB.png}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/twitter/Twitter_volume_KO.png}
  \end{subfigure}

  \medskip

  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/twitter/Twitter_volume_PFE.png}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.5	\textwidth}
    \centering
    \includegraphics[width=\linewidth]{images/dataAnomalies/twitter/Twitter_volume_CRM.png}
  \end{subfigure}
  \caption{Examples of point anomalies from twitter volume dataset}
  \label{AwsConceptDrift}
\end{figure}

Another important benefit is the availability of labeled data. Other then the seven real life time series, for which the cause of anomaly is known, all others were labeled diligently using a labelling process. \\
\break
Three different human labelers labeled the dataset. Each labeler would read each file using all available tools specially visualization and with some external human expertise in the field, label the dataset. The timestamp at the start of each anomaly is noted. This way there is a data file describing raw labels by each labeler. Since there were three human labelers hence three different raw label files were created. Each raw label file contains file name as key and the values contain the start timestamps of anomaly. Next up all these files are merged into one using following merging strategy:
\begin{enumerate}
\item  For each given data file (i.e. the key), the start timestamps from all
the raw labels are collected into buckets with other start timestamps
within a certain range. That is, timestamps within a narrow range of
one another are bucketed together because they (very likely)
identify the same anomaly. Differences in anomaly start times
amongst labelers can be attributed to human error. The size of the
time range is set as 1/10 the size of an anomaly window (defined in
step 3 below), both preceding and following the given timestamp.
The rationale is straightforward: following the underlying
assumption anomalies are rare, if multiple anomaly labels fall within
the same window, they identify the same sequence of anomalous
data.
\item If a given bucket contains more timestamps (raw labels) than the
agreement threshold, it is classified as a true anomaly. The
standard threshold is 0.50, so a bucket must contain timestamps
from 50\% or more of the labelers in order to become a true
anomaly label .
\item Each true anomaly bucket is then merged into a single timestamp
based on frequency. That is, the timestamp which appears most
often within a bucket is chosen to represent the entire bucket. Ties
are determined by which timestamp occurs first. The resulting
timestamps are the ground truth labels marking the start of the true
anomalies.
\end{enumerate}
The combined labels are then converted into anomaly windows, indicated
by a beginning and ending timestamp. The motivation behind anomaly
windows is twofold. First, anomalous data often occurs over time, rather
than at a single point, and thus defining anomaly windows improves the
NAB scoring efficacy. Second, anomaly windows allow the DUT to not be
penalized during scoring if the DUT anomaly detections are slightly before
or after the ground truth. We want these windows to be large enough to
allow early detection of anomalies, but not so large as to artificially boost
the score of inaccurate detectors. That is, the windows give the benefit of
the doubt to the detector, but not so much that false positives would count
as true positives. The anomaly windows are calculated using the following
algorithm:
\begin{enumerate}
\item The total amount of window length in a single data file was chosen
to be 10\% of the data file length. For instance, if a data file contains
4000 data points, then the total amount of relaxation shared by all
anomaly windows in the data file is 0.1*4000, or 400 data points.
The 10\% parameter was validated by qualitatively inspecting the
dataset, and experimenting with a range of values showed no
significant affect on the resulting scores, likely due to the scaled
sigmoid scoring function (described later).
\item The total window length for a data file is then divided by the total
number of ground truth anomalies in the data file, and the resulting
number of data points makeup each anomaly window, 1/2 before
the start of the window, and 1/2 at the end of the window. For
instance, if the data file above has four ground truth anomalies,
then each anomaly window is 400/4, or 100 data points – i.e. 50
data points both before and after the truth anomaly data point.
\item If two ground truth anomalies are in close proximity such that they
overlap, the anomalies are combined into one large window. The
rationale being if multiple anomalies fall within the same window
length, we assume they identify the same anomalous data.
\end{enumerate}
Thus ground labels of anomalies are obtained. 


\section{Results}

\subsection{Comparing with others}
\begin{table}[H]
\centering
\begin{tabular}{llll}
 \hline  
\textbf{Algorithm} & low FN rate & low FP rate & Standard  \\
 \hline  
numenta   & 74.3202     & 63.1168 & 70.1011 \\
 \hline  
contextOSE          & 73.1817     & 66.9771 & 69.8996           \\
 \hline  
htmjava          & 70.4241     & 53.2569 & 65.5499        \\
\hline
numentaTM & 69.18506	& 56.6653	& 64.5534 \\
\hline
knncad & 64.8123 & 43.4085 & 57.9943\\
\hline
relativeEntropy & 58.8423 & 47.5984 & 54.6427\\
\hline
randomCutForest & 59.7488 & 38.3608 & 51.7171\\
\hline
twitterADVec & 53.5011 & 33.6101 & 47.062\\
\hline
predictionMultiStepLSTMMultiStep1Window50 & 59.3125 & 43.5927 & 43.2791\\
\hline
windowedGaussian & 47.41 & 20.868 & 39.6495\\
 \hline
predictionMultiStepLSTMMultiStep5Window20 & 41.6451 & 35.4072 & 39.1918\\
 \hline
predictionMultiStepLSTMMultiStep5Window20 & 40.8274 & 34.6116 & 38.3963\\
 \hline
predictionMultiStepLSTMMultiStep1Window200 & 40.2705 & 31.1383 & 36.0246\\
 \hline
skyline & 44.481 & 27.0812 & 35.687\\
 \hline
predictionMultiStepNNMultiStep4Window50 & 29.1037 & 25.6366 & 24.4352\\
 \hline
predictionMultiStepCNNMultiStep5Window30 & 21.228 & 19.6188 & 20.9474\\
 \hline
predictionMultiStepCNNMultiStep5Window20 & 21.5211 & 18.142 & 19.6384\\
 \hline
predictionMultiStepNNMultiStep5Window30 & 19.4988 & 18.0512 & 19.5921\\
 \hline
random & 27.201 & 5.76368 & 17.6554\\
 \hline
expose & 26.9209 & 3.19093 & 16.4367\\
 


  
\end{tabular}
\end{table}


\section{Conclusion and Discussion}

\section{Experiment Infrastructure}

\subsection{Experiment Management using MLflow}

\subsection{Parallel execution using Docker}

\section{Best practices}
Following steps were taken to maximize the efficiency and speed of research:
\begin{enumerate}
	\item Use version control to track the code and share between different devices.
	\item Separate code from data. This will keep the code base small and easy to debug.
	\item Separate input data,working data and output data.
	\begin{itemize}
		\item \textbf{Input Data:} Input data-set that never change. For my case it is NAB and other external datasets.
		\item \textbf{Working Data:} nothing for now.
		\item \textbf{Output Data:} Results and threshold profiles in my case. 
	\end{itemize}
	\item Separate options from parameter. This is important:
 	\begin{itemize}
 		\item Options specify how your algorithm should run. For example data path, working directory and result directory path, epochs, learning rate and so on.
 		\item parameters are the result of training data. it includes the score and hyper-parameters. 
 	\end{itemize}
	
\end{enumerate}

\subsection{Moving from jupyterlab to pycharm}
While working with jupyterlab notebook following routine was followed:
1- Load data with sample function
2- Write an algorithm
3- Test the results
4- Write general executeable .py file.
5- Get results on server

Since we needed to track change on two different places,
it was becoming harder to track the bugs and improve on efficiency.
That's why pycharm was selected to create executeable files and test
algorithms at the same time.
\section{Reference Usage}

\section{References}
\begingroup
\nocite{*}
\renewcommand{\section}[2]{}
\bibliographystyle{IEEEtran}
\bibliography{third}
\endgroup
\end{document}
