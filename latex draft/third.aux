\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{KaiserGSVPJU17}
\citation{KaiserGSVPJU17}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples decoded from a single MultiModel trained jointly on 8 tasks. Red depicts a language modality while blue depicts a categorical modality. \cite  {KaiserGSVPJU17}}}{4}{figure.1}}
\citation{KaiserGSVPJU17}
\citation{KaiserGSVPJU17}
\@writefile{toc}{\contentsline {section}{\numberline {2}Multi-Model Architecture}{5}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The MultiModel, with modality-nets, an encoder, and an autoregressive decoder \cite  {KaiserGSVPJU17}}}{5}{figure.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Components}{5}{subsection.2.1}}
\citation{KaiserGSVPJU17}
\citation{KaiserGSVPJU17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Component Models Architecture}{6}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Encoder Architecture. \cite  {KaiserGSVPJU17}}}{6}{figure.3}}
\citation{KaiserGSVPJU17}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces I/O mixer architecture. \cite  {KaiserGSVPJU17}}}{7}{figure.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Base Component Architecture}{7}{subsection.2.3}}
\citation{KaiserGSVPJU17}
\citation{KaiserGSVPJU17}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Decoder architecture\cite  {KaiserGSVPJU17}}}{8}{figure.5}}
\citation{KaiserGSVPJU17}
\citation{Chollet16a}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Attention Architecture. \cite  {KaiserGSVPJU17}}}{9}{figure.6}}
\citation{ShazeerMMDLHD17}
\citation{KaiserGSVPJU17}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Dot-Product Attention Architecture. \cite  {KaiserGSVPJU17}}}{10}{figure.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Modality Nets}{10}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces ConvBlock Architecture. \cite  {KaiserGSVPJU17}}}{11}{figure.8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Language Modality Net}{11}{subsubsection.2.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Image Modality Net}{11}{subsubsection.2.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Categorical Modality Net}{12}{subsubsection.2.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Audio Modality Net}{12}{subsubsection.2.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Mixture of Experts (MoE) Architecture. \cite  {KaiserGSVPJU17}}}{12}{figure.9}}
\citation{SzegedyIV16}
\citation{ShazeerMMDLHD17}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments}{13}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Datasets}{13}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Basic Questions}{13}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Comparing MultiModel to state-of-the-art from \cite  {SzegedyIV16} and \cite  {ShazeerMMDLHD17}}}{14}{figure.10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Results}{14}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Comparison of the MultiModel trained jointly on 8 tasks and separately on each task}}{14}{figure.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Results on training parsing alone, with ImageNet, and with 8 other tasks. We report log-perplexity, per-token accuracy, and the percentage of fully correct parse trees.}}{15}{figure.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Ablating mixture-of-experts and attention from MultiModel training.}}{15}{figure.13}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{15}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussions and Remarks}{16}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}General Review}{16}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Technical Review}{16}{subsection.5.2}}
\citation{*}
\bibstyle{IEEEtrans}
\bibdata{third}
\bibcite{Chollet16a}{1}
\bibcite{url2}{2}
\bibcite{url1}{3}
\bibcite{KaiserGSVPJU17}{4}
\bibcite{ShazeerMMDLHD17}{5}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{17}{section.6}}
